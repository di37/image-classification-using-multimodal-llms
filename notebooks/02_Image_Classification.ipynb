{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_classification import animal_classifier_ollama, animal_classifier_openai, animal_classifier_gemini\n",
    "from utilities import animal_classifier\n",
    "from image_classification import SYSTEM_PROMPT, USER_PROMPT\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_ollama = ['llama3.2-vision', 'minicpm-v', 'llava-llama3', 'llava', 'llava:13b']\n",
    "models_openai = ['gpt-4o-mini', 'gpt-4o']\n",
    "models_gemini = ['gemini-1.5-pro', 'gemini-exp-1206', 'gemini-exp-1121', 'gemini-1.5-flash-8b', 'gemini-1.5-flash']\n",
    "image_path = 'data/animals/animals/seahorse/0a49b5e17d.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: llama3.2-vision\n",
      "Response: seahorse\n",
      "\n",
      "Model: minicpm-v\n",
      "Response: seahorse\n",
      "\n",
      "Model: llava-llama3\n",
      "Response: seahorse\n",
      "\n",
      "Model: llava\n",
      "Response: seahorse\n",
      "\n",
      "Model: llava:13b\n",
      "Response: seahorse\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models_ollama:\n",
    "    response = animal_classifier_ollama(model=model, image_path=image_path, system_prompt=SYSTEM_PROMPT, user_prompt=USER_PROMPT)\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Response: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4o-mini\n",
      "Response: seahorse\n",
      "\n",
      "Model: gpt-4o\n",
      "Response: seahorse\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models_openai:\n",
    "    response = animal_classifier_openai(model=model, image_path=image_path, system_prompt=SYSTEM_PROMPT, user_prompt=USER_PROMPT)\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Response: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gemini-1.5-pro\n",
      "Response: seahorse\n",
      "\n",
      "Model: gemini-exp-1206\n",
      "Response: seahorse\n",
      "\n",
      "Model: gemini-exp-1121\n",
      "Response: seahorse\n",
      "\n",
      "Model: gemini-1.5-flash-8b\n",
      "Response: seahorse\n",
      "\n",
      "Model: gemini-1.5-flash\n",
      "Response: seahorse\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models_gemini:\n",
    "    response = animal_classifier_gemini(model=model, image_path=image_path, system_prompt=SYSTEM_PROMPT, user_prompt=USER_PROMPT)\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Response: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_animals = \"data/sampled_animals.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>path</th>\n",
       "      <th>size_kb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>okapi</td>\n",
       "      <td>./data/animals/animals/okapi/4e8b303dc1.jpg</td>\n",
       "      <td>622.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>okapi</td>\n",
       "      <td>./data/animals/animals/okapi/4ceab227d9.jpg</td>\n",
       "      <td>298.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>okapi</td>\n",
       "      <td>./data/animals/animals/okapi/1e06facf31.jpg</td>\n",
       "      <td>23.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>okapi</td>\n",
       "      <td>./data/animals/animals/okapi/45f17f3f77.jpg</td>\n",
       "      <td>13.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>okapi</td>\n",
       "      <td>./data/animals/animals/okapi/49f6929ec7.jpg</td>\n",
       "      <td>22.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  animal                                         path  size_kb\n",
       "0  okapi  ./data/animals/animals/okapi/4e8b303dc1.jpg   622.17\n",
       "1  okapi  ./data/animals/animals/okapi/4ceab227d9.jpg   298.54\n",
       "2  okapi  ./data/animals/animals/okapi/1e06facf31.jpg    23.29\n",
       "3  okapi  ./data/animals/animals/okapi/45f17f3f77.jpg    13.73\n",
       "4  okapi  ./data/animals/animals/okapi/49f6929ec7.jpg    22.25"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(sampled_animals)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   animal   250 non-null    object \n",
      " 1   path     250 non-null    object \n",
      " 2   size_kb  250 non-null    float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['llama3.2-vision', 'minicpm-v', 'llava-llama3', 'llava', 'llava:13b']\n",
    "for model in models:\n",
    "    df[f'{model}_result'] = None\n",
    "    results = []\n",
    "    for index, row in df.iterrows():\n",
    "        animal = row['animal']\n",
    "        image_path = row['path']\n",
    "        result = animal_classifier(model=model, image_path=image_path)\n",
    "        results.append(result)\n",
    "    df[f'{model}_result'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seahorse\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(image_path)\n",
    "model = genai.GenerativeModel(model_name = \"gemini-1.5-pro\")\n",
    "prompt = SYSTEM_PROMPT + USER_PROMPT\n",
    "response = model.generate_content([image, prompt])\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
